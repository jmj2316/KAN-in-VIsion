{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyOcnm4ip+tbiaju4lIHoj41"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pynvml"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPUEMG6hLhD0",
        "outputId": "895a4012-8e49-4256-871b-1e004f95794f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pynvml\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/53.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pynvml\n",
            "Successfully installed pynvml-11.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6V5Hb6cksC2",
        "outputId": "32252d03-5be4-4dcf-c343-e6a7aa1a4061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Jun 20 23:58:41 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  NVIDIA L4                      Off | 00000000:00:03.0 Off |                    0 |\n",
            "| N/A   49C    P8              13W /  72W |      1MiB / 23034MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "class KANLinear(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        in_features,\n",
        "        out_features,\n",
        "        grid_size=5,\n",
        "        spline_order=3,\n",
        "        scale_noise=0.1,\n",
        "        scale_base=1.0,\n",
        "        scale_spline=1.0,\n",
        "        enable_standalone_scale_spline=True,\n",
        "        base_activation=nn.SiLU,\n",
        "        grid_eps=0.02,\n",
        "        grid_range=[-1, 1],\n",
        "    ):\n",
        "        super(KANLinear, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.grid_size = grid_size\n",
        "        self.spline_order = spline_order\n",
        "\n",
        "        h = (grid_range[1] - grid_range[0]) / grid_size\n",
        "        grid = (\n",
        "            (\n",
        "                torch.arange(-spline_order, grid_size + spline_order + 1) * h\n",
        "                + grid_range[0]\n",
        "            )\n",
        "            .expand(in_features, -1)\n",
        "            .contiguous()\n",
        "        )\n",
        "        self.register_buffer(\"grid\", grid)\n",
        "\n",
        "        self.base_weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
        "        self.spline_weight = nn.Parameter(\n",
        "            torch.Tensor(out_features, in_features, grid_size + spline_order)\n",
        "        )\n",
        "        if enable_standalone_scale_spline:\n",
        "            self.spline_scaler = nn.Parameter(\n",
        "                torch.Tensor(out_features, in_features)\n",
        "            )\n",
        "\n",
        "        self.scale_noise = scale_noise\n",
        "        self.scale_base = scale_base\n",
        "        self.scale_spline = scale_spline\n",
        "        self.enable_standalone_scale_spline = enable_standalone_scale_spline\n",
        "        self.base_activation = base_activation()\n",
        "        self.grid_eps = grid_eps\n",
        "\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        nn.init.kaiming_uniform_(self.base_weight, a=math.sqrt(5) * self.scale_base)\n",
        "        with torch.no_grad():\n",
        "            noise = (\n",
        "                (\n",
        "                    torch.rand(self.grid_size + 1, self.in_features, self.out_features)\n",
        "                    - 1 / 2\n",
        "                )\n",
        "                * self.scale_noise\n",
        "                / self.grid_size\n",
        "            )\n",
        "            self.spline_weight.data.copy_(\n",
        "                (self.scale_spline if not self.enable_standalone_scale_spline else 1.0)\n",
        "                * self.curve2coeff(\n",
        "                    self.grid.T[self.spline_order : -self.spline_order],\n",
        "                    noise,\n",
        "                )\n",
        "            )\n",
        "            if self.enable_standalone_scale_spline:\n",
        "                nn.init.kaiming_uniform_(self.spline_scaler, a=math.sqrt(5) * self.scale_spline)\n",
        "\n",
        "    def b_splines(self, x):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "\n",
        "        grid = self.grid\n",
        "        x = x.unsqueeze(-1)\n",
        "        bases = ((x >= grid[:, :-1]) & (x < grid[:, 1:])).to(x.dtype)\n",
        "        for k in range(1, self.spline_order + 1):\n",
        "            bases = (\n",
        "                (x - grid[:, : -(k + 1)])\n",
        "                / (grid[:, k:-1] - grid[:, : -(k + 1)])\n",
        "                * bases[:, :, :-1]\n",
        "            ) + (\n",
        "                (grid[:, k + 1 :] - x)\n",
        "                / (grid[:, k + 1 :] - grid[:, 1:(-k)])\n",
        "                * bases[:, :, 1:]\n",
        "            )\n",
        "\n",
        "        assert bases.size() == (\n",
        "            x.size(0),\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return bases.contiguous()\n",
        "\n",
        "    def curve2coeff(self, x, y):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        assert y.size() == (x.size(0), self.in_features, self.out_features)\n",
        "\n",
        "        A = self.b_splines(x).transpose(0, 1)\n",
        "        B = y.transpose(0, 1)\n",
        "        solution = torch.linalg.lstsq(A, B).solution\n",
        "        result = solution.permute(2, 0, 1)\n",
        "\n",
        "        assert result.size() == (\n",
        "            self.out_features,\n",
        "            self.in_features,\n",
        "            self.grid_size + self.spline_order,\n",
        "        )\n",
        "        return result.contiguous()\n",
        "\n",
        "    @property\n",
        "    def scaled_spline_weight(self):\n",
        "        return self.spline_weight * (\n",
        "            self.spline_scaler.unsqueeze(-1)\n",
        "            if self.enable_standalone_scale_spline\n",
        "            else 1.0\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        original_shape = x.shape\n",
        "        if x.dim() == 3:\n",
        "            x = x.reshape(-1, x.size(-1))  # Flatten to 2D tensor\n",
        "\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        self.acts = self.base_activation(x)  # Store activations\n",
        "\n",
        "\n",
        "        base_output = F.linear(self.base_activation(x), self.base_weight)\n",
        "        spline_output = F.linear(\n",
        "            self.b_splines(x).view(x.size(0), -1),\n",
        "            self.scaled_spline_weight.view(self.out_features, -1),\n",
        "        )\n",
        "        output = base_output + spline_output\n",
        "\n",
        "        if len(original_shape) == 3:\n",
        "            output = output.reshape(original_shape[0], original_shape[1], -1)  # Reshape back to 3D tensor\n",
        "\n",
        "        return output\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def update_grid(self, x, margin=0.01):\n",
        "        assert x.dim() == 2 and x.size(1) == self.in_features\n",
        "        batch = x.size(0)\n",
        "\n",
        "        splines = self.b_splines(x)\n",
        "        splines = splines.permute(1, 0, 2)\n",
        "        orig_coeff = self.scaled_spline_weight\n",
        "        orig_coeff = orig_coeff.permute(1, 2, 0)\n",
        "        unreduced_spline_output = torch.bmm(splines, orig_coeff)\n",
        "        unreduced_spline_output = unreduced_spline_output.permute(1, 0, 2)\n",
        "\n",
        "        x_sorted = torch.sort(x, dim=0)[0]\n",
        "        grid_adaptive = x_sorted[\n",
        "            torch.linspace(\n",
        "                0, batch - 1, self.grid_size + 1, dtype=torch.int64, device=x.device\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        uniform_step = (x_sorted[-1] - x_sorted[0] + 2 * margin) / self.grid_size\n",
        "        grid_uniform = (\n",
        "            torch.arange(\n",
        "                self.grid_size + 1, dtype=torch.float32, device=x.device\n",
        "            ).unsqueeze(1)\n",
        "            * uniform_step\n",
        "            + x_sorted[0]\n",
        "            - margin\n",
        "        )\n",
        "\n",
        "        grid = self.grid_eps * grid_uniform + (1 - self.grid_eps) * grid_adaptive\n",
        "        grid = torch.cat(\n",
        "            [\n",
        "                grid[:1]\n",
        "                - uniform_step\n",
        "                * torch.arange(self.spline_order, 0, -1, device=x.device).unsqueeze(1),\n",
        "                grid,\n",
        "                grid[-1:]\n",
        "                + uniform_step\n",
        "                * torch.arange(1, self.spline_order + 1, device=x.device).unsqueeze(1),\n",
        "            ],\n",
        "            dim=0,\n",
        "        )\n",
        "\n",
        "        self.grid.copy_(grid.T)\n",
        "        self.spline_weight.data.copy_(self.curve2coeff(x, unreduced_spline_output))\n",
        "\n",
        "    def regularization_loss(self, regularize_activation=1.0, regularize_entropy=1.0):\n",
        "        l1_fake = self.spline_weight.abs().mean(-1)\n",
        "        regularization_loss_activation = l1_fake.sum()\n",
        "        p = l1_fake / regularization_loss_activation\n",
        "        regularization_loss_entropy = -torch.sum(p * p.log())\n",
        "        return (\n",
        "            regularize_activation * regularization_loss_activation\n",
        "            + regularize_entropy * regularization_loss_entropy\n",
        "        )\n",
        "\n",
        "class ImageToPatches(nn.Module):\n",
        "    def __init__(self, patch_size):\n",
        "        super().__init__()\n",
        "        self.P = patch_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        P = self.P\n",
        "        B,C,H,W = x.shape                       # [B,C,H,W]                 4D Image\n",
        "        x = x.reshape(B,C, H//P, P , W//P, P)   # [B,C, H//P, P, W//P, P]   6D Patches\n",
        "        x = x.permute(0,2,4, 1,3,5)             # [B, H//P, W//P, C, P, P]  6D Swap Axes\n",
        "        x = x.reshape(B, H//P * W//P, C*P*P)    # [B, H//P * W//P, C*P*P]   3D Patches\n",
        "                                                # [B, n_tokens, n_pixels]\n",
        "        return x\n",
        "\n",
        "class PerPatchKAN(nn.Module):\n",
        "    def __init__(self, n_pixels, n_channel):\n",
        "        super().__init__()\n",
        "        self.kan = KANLinear(n_pixels, n_channel)\n",
        "\n",
        "    def forward(self, x):\n",
        "        output = self.kan(x)\n",
        "        return output  # x*w:  [B, n_tokens, n_pixels] x [n_pixels, n_channel]\n",
        "                       #       [B, n_tokens, n_channel]\n",
        "\n",
        "class TokenMixingKAN(nn.Module):\n",
        "    def __init__(self, n_tokens, n_channel, n_hidden):\n",
        "        super().__init__()\n",
        "        self.layer_norm = nn.LayerNorm([n_tokens, n_channel])\n",
        "        self.kan1 = KANLinear(n_tokens, n_hidden)\n",
        "        self.kan2 = KANLinear(n_hidden, n_tokens)\n",
        "        self.activations = None\n",
        "\n",
        "    def forward(self, X):\n",
        "        z = self.layer_norm(X)                  # z:    [B, n_tokens, n_channel]\n",
        "        z = z.permute(0, 2, 1)                  # z:    [B, n_channel, n_tokens]\n",
        "        z = self.kan1(z)                        # z:    [B, n_channel, n_hidden]\n",
        "        z = self.kan2(z)                        # z:    [B, n_hidden, n_tokens]\n",
        "        z = z.permute(0, 2, 1)                  # z:    [B, n_tokens, n_channel]\n",
        "        U = X + z                               # U:    [B, n_tokens, n_channel]\n",
        "        self.activations = U  # Store activations\n",
        "        return U\n",
        "\n",
        "class ChannelMixingKAN(nn.Module):\n",
        "    def __init__(self, n_tokens, n_channel, n_hidden):\n",
        "        super().__init__()\n",
        "        self.layer_norm = nn.LayerNorm([n_tokens, n_channel])\n",
        "        self.kan3 = KANLinear(n_channel, n_hidden)\n",
        "        self.kan4 = KANLinear(n_hidden, n_channel)\n",
        "        self.activations = None\n",
        "\n",
        "    def forward(self, U):\n",
        "        z = self.layer_norm(U)                  # z: [B, n_tokens, n_channel]\n",
        "        z = self.kan3(z)                        # z: [B, n_tokens, n_hidden]\n",
        "        z = self.kan4(z)                        # z: [B, n_tokens, n_channel]\n",
        "        Y = U + z                               # Y: [B, n_tokens, n_channel]\n",
        "        self.activations = Y  # Store activations\n",
        "        return Y\n",
        "\n",
        "class OutputKAN(nn.Module):\n",
        "    def __init__(self, n_tokens, n_channel, n_output):\n",
        "        super().__init__()\n",
        "        self.layer_norm = nn.LayerNorm([n_tokens, n_channel])\n",
        "        self.global_avg_pool = nn.AdaptiveAvgPool1d(1)  # Global average pooling\n",
        "        self.out_kan = KANLinear(n_channel, n_output)\n",
        "        self.activations = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.layer_norm(x)                  # x: [B, n_tokens, n_channel]\n",
        "        x = x.permute(0, 2, 1)                  # [B, n_tokens, n_channel] -> [B, n_channel, n_tokens]\n",
        "        x = self.global_avg_pool(x)             # [B, n_channel, n_tokens] -> [B, n_channel, 1]\n",
        "        x = x.squeeze(-1)                       # [B, n_channel, 1] -> [B, n_channel]\n",
        "        output = self.out_kan(x)                # x: [B, n_output]\n",
        "        self.activations = self.out_kan.acts  # Store activations\n",
        "        return output\n",
        "\n",
        "class KAN_Mixer(nn.Module):\n",
        "    def __init__(self, n_layers, n_channel, n_hidden, n_output, image_size, patch_size, n_image_channel):\n",
        "        super().__init__()\n",
        "\n",
        "        n_tokens = (image_size // patch_size)**2\n",
        "        n_pixels = n_image_channel * patch_size**2\n",
        "\n",
        "        self.ImageToPatch = ImageToPatches(patch_size = patch_size)\n",
        "        self.PerPatchKAN = PerPatchKAN(n_pixels, n_channel)\n",
        "        self.MixerStack = nn.Sequential(*[\n",
        "            nn.Sequential(\n",
        "                TokenMixingKAN(n_tokens, n_channel, n_hidden),\n",
        "                ChannelMixingKAN(n_tokens, n_channel, n_hidden)\n",
        "            ) for _ in range(n_layers)\n",
        "        ])\n",
        "        self.OutputKAN = OutputKAN(n_tokens, n_channel, n_output)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.ImageToPatch(x)\n",
        "        x = self.PerPatchKAN(x)\n",
        "        x = self.MixerStack(x)\n",
        "        return self.OutputKAN(x)\n",
        "\n",
        "# Example usage:\n",
        "n_layers = 2\n",
        "n_channel = 16\n",
        "n_hidden = 32\n",
        "n_output = 10\n",
        "image_size = 32\n",
        "patch_size = 2\n",
        "n_image_channel = 3\n",
        "\n",
        "model = KAN_Mixer(n_layers, n_channel, n_hidden, n_output, image_size, patch_size, n_image_channel)\n",
        "\n",
        "# Create a dummy input tensor with the shape [batch_size, n_image_channel, image_height, image_width]\n",
        "x = torch.randn(1, n_image_channel, image_size, image_size)\n",
        "\n",
        "# Forward pass\n",
        "output = model(x)\n",
        "print(output.shape)  # Should be [batch_size, n_output]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJrl9jRrmVhi",
        "outputId": "57505c29-3c79-469f-d9f4-c869b82790df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10, CIFAR100, MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "\n",
        "# The full classes are assumed to be already provided based on your previous implementation\n",
        "\n",
        "# Define transformations for the dataset\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "test_transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_mnist = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "def get_dataloaders(dataset, transform, test_transform, batch_size=32):\n",
        "    if dataset == 'CIFAR10':\n",
        "        train_dataset = CIFAR10(root='data', train=True, transform=transform, download=True)\n",
        "        test_dataset = CIFAR10(root='data', train=False, transform=test_transform, download=True)\n",
        "    elif dataset == 'CIFAR100':\n",
        "        train_dataset = CIFAR100(root='data', train=True, transform=transform, download=True)\n",
        "        test_dataset = CIFAR100(root='data', train=False, transform=test_transform, download=True)\n",
        "    elif dataset == 'MNIST':\n",
        "        train_dataset = MNIST(root='data', train=True, transform=transform, download=True)\n",
        "        test_dataset = MNIST(root='data', train=False, transform=test_transform, download=True)\n",
        "    else:\n",
        "        raise ValueError(\"Dataset not supported\")\n",
        "\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "def calculate_memory():\n",
        "    return psutil.virtual_memory()._asdict()\n",
        "\n",
        "def train_and_evaluate(model, train_loader, val_loader, device, dataset, n_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.to(device)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_time = end_time - start_time\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                pred = outputs.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_accuracy = correct / len(val_loader.dataset)\n",
        "\n",
        "        gpu_memory_allocated = torch.cuda.memory_allocated() / 1024**2\n",
        "        gpu_memory_reserved = torch.cuda.memory_reserved() / 1024**2\n",
        "\n",
        "        results.append({\n",
        "            'dataset': dataset,\n",
        "            'epoch': epoch + 1,\n",
        "            'epoch_time': epoch_time,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_accuracy,\n",
        "            'gpu_memory_allocated_MB': gpu_memory_allocated,\n",
        "            'gpu_memory_reserved_MB': gpu_memory_reserved\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{n_epochs} - Time: {epoch_time:.2f}s')\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "        print(f'GPU memory usage: {gpu_memory_allocated:.2f} MB')\n",
        "        print(f'GPU memory reserved: {gpu_memory_reserved:.2f} MB')\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return results\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    start_time = time.time()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            test_loss += criterion(outputs, labels).item()\n",
        "            pred = outputs.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    end_time = time.time()\n",
        "    test_time = end_time - start_time\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = correct / len(test_loader.dataset)\n",
        "\n",
        "    gpu_memory_allocated = torch.cuda.memory_allocated() / 1024**2\n",
        "    gpu_memory_reserved = torch.cuda.memory_reserved() / 1024**2\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
        "    print(f'Test Time: {test_time:.2f}s')\n",
        "    print(f'GPU memory usage during test: {gpu_memory_allocated:.2f} MB')\n",
        "    print(f'GPU memory reserved during test: {gpu_memory_reserved:.2f} MB')\n",
        "\n",
        "    return test_loss, test_accuracy, test_time, gpu_memory_allocated, gpu_memory_reserved\n",
        "\n",
        "def main():\n",
        "    datasets = ['CIFAR10', 'CIFAR100', 'MNIST']\n",
        "    batch_size = 32\n",
        "    n_epochs = 10\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for dataset in datasets:\n",
        "        print(f\"Training on {dataset}\")\n",
        "        if dataset == 'MNIST':\n",
        "            train_loader, val_loader, test_loader = get_dataloaders(dataset, transform_mnist, transform_mnist, batch_size)\n",
        "        else:\n",
        "            train_loader, val_loader, test_loader = get_dataloaders(dataset, transform_cifar, test_transform_cifar, batch_size)\n",
        "\n",
        "        n_layers = 2\n",
        "        n_channel = 16\n",
        "        n_hidden = 32\n",
        "        n_output = 10 if dataset != 'CIFAR100' else 100\n",
        "        image_size = 32\n",
        "        patch_size = 2\n",
        "        n_image_channel = 3 if dataset != 'MNIST' else 1\n",
        "\n",
        "        model = KAN_Mixer(n_layers, n_channel, n_hidden, n_output, image_size, patch_size, n_image_channel)\n",
        "\n",
        "        # Reset GPU memory stats\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        train_results = train_and_evaluate(model, train_loader, val_loader, device, dataset, n_epochs)\n",
        "        test_loss, test_accuracy, test_time, test_gpu_allocated, test_gpu_reserved = test(model, test_loader, device)\n",
        "\n",
        "        for result in train_results:\n",
        "            result.update({\n",
        "                'test_loss': test_loss,\n",
        "                'test_accuracy': test_accuracy,\n",
        "                'test_time': test_time,\n",
        "                'test_gpu_memory_allocated_MB': test_gpu_allocated,\n",
        "                'test_gpu_memory_reserved_MB': test_gpu_reserved\n",
        "            })\n",
        "\n",
        "        all_results.extend(train_results)\n",
        "\n",
        "    # Save all results to one DataFrame\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv('all_datasets_results.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y453d8kMn-sI",
        "outputId": "c1ccdb18-0b03-42d0-dcf4-fd688d051c22"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on CIFAR10\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:04<00:00, 41973103.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-10-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Epoch 1/10 - Time: 43.92s\n",
            "Validation Loss: 0.0517, Validation Accuracy: 0.3934\n",
            "GPU memory usage: 26.98 MB\n",
            "GPU memory reserved: 418.00 MB\n",
            "Epoch 2/10 - Time: 42.86s\n",
            "Validation Loss: 0.0473, Validation Accuracy: 0.4511\n",
            "GPU memory usage: 26.98 MB\n",
            "GPU memory reserved: 418.00 MB\n",
            "Epoch 3/10 - Time: 42.64s\n",
            "Validation Loss: 0.0451, Validation Accuracy: 0.4739\n",
            "GPU memory usage: 26.98 MB\n",
            "GPU memory reserved: 418.00 MB\n",
            "Epoch 4/10 - Time: 42.84s\n",
            "Validation Loss: 0.0424, Validation Accuracy: 0.5134\n",
            "GPU memory usage: 26.98 MB\n",
            "GPU memory reserved: 418.00 MB\n",
            "Epoch 5/10 - Time: 42.88s\n",
            "Validation Loss: 0.0414, Validation Accuracy: 0.5253\n",
            "GPU memory usage: 26.98 MB\n",
            "GPU memory reserved: 418.00 MB\n",
            "Epoch 6/10 - Time: 42.57s\n",
            "Validation Loss: 0.0404, Validation Accuracy: 0.5322\n",
            "GPU memory usage: 26.98 MB\n",
            "GPU memory reserved: 418.00 MB\n",
            "Epoch 7/10 - Time: 42.50s\n",
            "Validation Loss: 0.0399, Validation Accuracy: 0.5358\n",
            "GPU memory usage: 26.98 MB\n",
            "GPU memory reserved: 418.00 MB\n",
            "Epoch 8/10 - Time: 42.45s\n",
            "Validation Loss: 0.0387, Validation Accuracy: 0.5563\n",
            "GPU memory usage: 26.98 MB\n",
            "GPU memory reserved: 418.00 MB\n",
            "Epoch 9/10 - Time: 42.47s\n",
            "Validation Loss: 0.0391, Validation Accuracy: 0.5504\n",
            "GPU memory usage: 26.98 MB\n",
            "GPU memory reserved: 418.00 MB\n",
            "Epoch 10/10 - Time: 42.39s\n",
            "Validation Loss: 0.0377, Validation Accuracy: 0.5675\n",
            "GPU memory usage: 26.98 MB\n",
            "GPU memory reserved: 418.00 MB\n",
            "Test Loss: 0.0363, Test Accuracy: 0.5786\n",
            "Test Time: 5.03s\n",
            "GPU memory usage during test: 23.98 MB\n",
            "GPU memory reserved during test: 84.00 MB\n",
            "Training on CIFAR100\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169001437/169001437 [00:03<00:00, 44250469.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/cifar-100-python.tar.gz to data\n",
            "Files already downloaded and verified\n",
            "Epoch 1/10 - Time: 42.78s\n",
            "Validation Loss: 0.1231, Validation Accuracy: 0.0964\n",
            "GPU memory usage: 27.20 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 2/10 - Time: 42.78s\n",
            "Validation Loss: 0.1156, Validation Accuracy: 0.1297\n",
            "GPU memory usage: 27.20 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 3/10 - Time: 42.73s\n",
            "Validation Loss: 0.1122, Validation Accuracy: 0.1492\n",
            "GPU memory usage: 27.20 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 4/10 - Time: 42.68s\n",
            "Validation Loss: 0.1086, Validation Accuracy: 0.1641\n",
            "GPU memory usage: 27.20 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 5/10 - Time: 42.61s\n",
            "Validation Loss: 0.1064, Validation Accuracy: 0.1764\n",
            "GPU memory usage: 27.20 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 6/10 - Time: 42.51s\n",
            "Validation Loss: 0.1053, Validation Accuracy: 0.1918\n",
            "GPU memory usage: 27.20 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 7/10 - Time: 42.74s\n",
            "Validation Loss: 0.1035, Validation Accuracy: 0.1910\n",
            "GPU memory usage: 27.20 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 8/10 - Time: 42.85s\n",
            "Validation Loss: 0.1023, Validation Accuracy: 0.2018\n",
            "GPU memory usage: 27.20 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 9/10 - Time: 42.82s\n",
            "Validation Loss: 0.1014, Validation Accuracy: 0.2099\n",
            "GPU memory usage: 27.20 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 10/10 - Time: 42.67s\n",
            "Validation Loss: 0.1001, Validation Accuracy: 0.2154\n",
            "GPU memory usage: 27.20 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Test Loss: 0.0995, Test Accuracy: 0.2201\n",
            "Test Time: 5.05s\n",
            "GPU memory usage during test: 24.09 MB\n",
            "GPU memory reserved during test: 82.00 MB\n",
            "Training on MNIST\n",
            "Epoch 1/10 - Time: 44.44s\n",
            "Validation Loss: 0.0049, Validation Accuracy: 0.9528\n",
            "GPU memory usage: 29.90 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 2/10 - Time: 44.51s\n",
            "Validation Loss: 0.0037, Validation Accuracy: 0.9665\n",
            "GPU memory usage: 29.90 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 3/10 - Time: 44.40s\n",
            "Validation Loss: 0.0031, Validation Accuracy: 0.9720\n",
            "GPU memory usage: 29.90 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 4/10 - Time: 44.27s\n",
            "Validation Loss: 0.0032, Validation Accuracy: 0.9697\n",
            "GPU memory usage: 29.90 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 5/10 - Time: 44.50s\n",
            "Validation Loss: 0.0028, Validation Accuracy: 0.9732\n",
            "GPU memory usage: 29.90 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 6/10 - Time: 44.42s\n",
            "Validation Loss: 0.0030, Validation Accuracy: 0.9732\n",
            "GPU memory usage: 29.90 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 7/10 - Time: 44.69s\n",
            "Validation Loss: 0.0030, Validation Accuracy: 0.9732\n",
            "GPU memory usage: 29.90 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 8/10 - Time: 44.58s\n",
            "Validation Loss: 0.0032, Validation Accuracy: 0.9733\n",
            "GPU memory usage: 29.90 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 9/10 - Time: 44.46s\n",
            "Validation Loss: 0.0034, Validation Accuracy: 0.9727\n",
            "GPU memory usage: 29.90 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Epoch 10/10 - Time: 44.52s\n",
            "Validation Loss: 0.0030, Validation Accuracy: 0.9746\n",
            "GPU memory usage: 29.90 MB\n",
            "GPU memory reserved: 428.00 MB\n",
            "Test Loss: 0.0030, Test Accuracy: 0.9765\n",
            "Test Time: 5.13s\n",
            "GPU memory usage during test: 23.72 MB\n",
            "GPU memory reserved during test: 82.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10, CIFAR100, MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "\n",
        "# The full classes are assumed to be already provided based on your previous implementation\n",
        "\n",
        "# Define transformations for the dataset\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "test_transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_mnist = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "def get_dataloaders(dataset, transform, test_transform, batch_size=32):\n",
        "    if dataset == 'CIFAR10':\n",
        "        train_dataset = CIFAR10(root='data', train=True, transform=transform, download=True)\n",
        "        test_dataset = CIFAR10(root='data', train=False, transform=test_transform, download=True)\n",
        "    elif dataset == 'CIFAR100':\n",
        "        train_dataset = CIFAR100(root='data', train=True, transform=transform, download=True)\n",
        "        test_dataset = CIFAR100(root='data', train=False, transform=test_transform, download=True)\n",
        "    elif dataset == 'MNIST':\n",
        "        train_dataset = MNIST(root='data', train=True, transform=transform, download=True)\n",
        "        test_dataset = MNIST(root='data', train=False, transform=test_transform, download=True)\n",
        "    else:\n",
        "        raise ValueError(\"Dataset not supported\")\n",
        "\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "def calculate_memory():\n",
        "    return psutil.virtual_memory()._asdict()\n",
        "\n",
        "def train_and_evaluate(model, train_loader, val_loader, device, dataset, n_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.to(device)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_time = end_time - start_time\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                pred = outputs.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_accuracy = correct / len(val_loader.dataset)\n",
        "\n",
        "        gpu_memory_allocated = torch.cuda.memory_allocated() / 1024**2\n",
        "        gpu_memory_reserved = torch.cuda.memory_reserved() / 1024**2\n",
        "\n",
        "        results.append({\n",
        "            'dataset': dataset,\n",
        "            'epoch': epoch + 1,\n",
        "            'epoch_time': epoch_time,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_accuracy,\n",
        "            'gpu_memory_allocated_MB': gpu_memory_allocated,\n",
        "            'gpu_memory_reserved_MB': gpu_memory_reserved\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{n_epochs} - Time: {epoch_time:.2f}s')\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "        print(f'GPU memory usage: {gpu_memory_allocated:.2f} MB')\n",
        "        print(f'GPU memory reserved: {gpu_memory_reserved:.2f} MB')\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return results\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    start_time = time.time()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            test_loss += criterion(outputs, labels).item()\n",
        "            pred = outputs.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    end_time = time.time()\n",
        "    test_time = end_time - start_time\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = correct / len(test_loader.dataset)\n",
        "\n",
        "    gpu_memory_allocated = torch.cuda.memory_allocated() / 1024**2\n",
        "    gpu_memory_reserved = torch.cuda.memory_reserved() / 1024**2\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
        "    print(f'Test Time: {test_time:.2f}s')\n",
        "    print(f'GPU memory usage during test: {gpu_memory_allocated:.2f} MB')\n",
        "    print(f'GPU memory reserved during test: {gpu_memory_reserved:.2f} MB')\n",
        "\n",
        "    return test_loss, test_accuracy, test_time, gpu_memory_allocated, gpu_memory_reserved\n",
        "\n",
        "def main():\n",
        "    datasets = ['CIFAR10', 'CIFAR100', 'MNIST']\n",
        "    batch_size = 32\n",
        "    n_epochs = 10\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for dataset in datasets:\n",
        "        print(f\"Training on {dataset}\")\n",
        "        if dataset == 'MNIST':\n",
        "            train_loader, val_loader, test_loader = get_dataloaders(dataset, transform_mnist, transform_mnist, batch_size)\n",
        "        else:\n",
        "            train_loader, val_loader, test_loader = get_dataloaders(dataset, transform_cifar, test_transform_cifar, batch_size)\n",
        "\n",
        "        n_layers = 2\n",
        "        n_channel = 32\n",
        "        n_hidden = 64\n",
        "        n_output = 10 if dataset != 'CIFAR100' else 100\n",
        "        image_size = 32\n",
        "        patch_size = 2\n",
        "        n_image_channel = 3 if dataset != 'MNIST' else 1\n",
        "\n",
        "        model = KAN_Mixer(n_layers, n_channel, n_hidden, n_output, image_size, patch_size, n_image_channel)\n",
        "\n",
        "        # Reset GPU memory stats\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        train_results = train_and_evaluate(model, train_loader, val_loader, device, dataset, n_epochs)\n",
        "        test_loss, test_accuracy, test_time, test_gpu_allocated, test_gpu_reserved = test(model, test_loader, device)\n",
        "\n",
        "        for result in train_results:\n",
        "            result.update({\n",
        "                'test_loss': test_loss,\n",
        "                'test_accuracy': test_accuracy,\n",
        "                'test_time': test_time,\n",
        "                'test_gpu_memory_allocated_MB': test_gpu_allocated,\n",
        "                'test_gpu_memory_reserved_MB': test_gpu_reserved\n",
        "            })\n",
        "\n",
        "        all_results.extend(train_results)\n",
        "\n",
        "    # Save all results to one DataFrame\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv('all_datasets_results.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SJm8XVpbHt-O",
        "outputId": "187fb274-58ad-43a7-f628-5daa505114b5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on CIFAR10\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/10 - Time: 43.28s\n",
            "Validation Loss: 0.0479, Validation Accuracy: 0.4397\n",
            "GPU memory usage: 55.68 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 2/10 - Time: 43.11s\n",
            "Validation Loss: 0.0440, Validation Accuracy: 0.4830\n",
            "GPU memory usage: 55.68 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 3/10 - Time: 43.20s\n",
            "Validation Loss: 0.0414, Validation Accuracy: 0.5222\n",
            "GPU memory usage: 55.68 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 4/10 - Time: 43.36s\n",
            "Validation Loss: 0.0396, Validation Accuracy: 0.5459\n",
            "GPU memory usage: 55.68 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 5/10 - Time: 43.15s\n",
            "Validation Loss: 0.0375, Validation Accuracy: 0.5691\n",
            "GPU memory usage: 55.68 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 6/10 - Time: 43.02s\n",
            "Validation Loss: 0.0368, Validation Accuracy: 0.5740\n",
            "GPU memory usage: 55.68 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 7/10 - Time: 43.24s\n",
            "Validation Loss: 0.0359, Validation Accuracy: 0.5934\n",
            "GPU memory usage: 55.68 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 8/10 - Time: 43.36s\n",
            "Validation Loss: 0.0353, Validation Accuracy: 0.5985\n",
            "GPU memory usage: 55.68 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 9/10 - Time: 43.10s\n",
            "Validation Loss: 0.0341, Validation Accuracy: 0.6086\n",
            "GPU memory usage: 55.68 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 10/10 - Time: 43.33s\n",
            "Validation Loss: 0.0333, Validation Accuracy: 0.6172\n",
            "GPU memory usage: 55.68 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Test Loss: 0.0322, Test Accuracy: 0.6300\n",
            "Test Time: 5.49s\n",
            "GPU memory usage during test: 49.38 MB\n",
            "GPU memory reserved during test: 202.00 MB\n",
            "Training on CIFAR100\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/10 - Time: 43.43s\n",
            "Validation Loss: 0.1177, Validation Accuracy: 0.1166\n",
            "GPU memory usage: 56.13 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 2/10 - Time: 43.40s\n",
            "Validation Loss: 0.1062, Validation Accuracy: 0.1791\n",
            "GPU memory usage: 56.13 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 3/10 - Time: 43.27s\n",
            "Validation Loss: 0.0999, Validation Accuracy: 0.2150\n",
            "GPU memory usage: 56.13 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 4/10 - Time: 43.19s\n",
            "Validation Loss: 0.0959, Validation Accuracy: 0.2325\n",
            "GPU memory usage: 56.13 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 5/10 - Time: 43.52s\n",
            "Validation Loss: 0.0935, Validation Accuracy: 0.2528\n",
            "GPU memory usage: 56.13 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 6/10 - Time: 43.41s\n",
            "Validation Loss: 0.0922, Validation Accuracy: 0.2552\n",
            "GPU memory usage: 56.13 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 7/10 - Time: 43.42s\n",
            "Validation Loss: 0.0893, Validation Accuracy: 0.2785\n",
            "GPU memory usage: 56.13 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 8/10 - Time: 43.46s\n",
            "Validation Loss: 0.0891, Validation Accuracy: 0.2845\n",
            "GPU memory usage: 56.13 MB\n",
            "GPU memory reserved: 846.00 MB\n",
            "Epoch 9/10 - Time: 43.06s\n",
            "Validation Loss: 0.0874, Validation Accuracy: 0.2916\n",
            "GPU memory usage: 56.13 MB\n",
            "GPU memory reserved: 848.00 MB\n",
            "Epoch 10/10 - Time: 43.22s\n",
            "Validation Loss: 0.0868, Validation Accuracy: 0.2934\n",
            "GPU memory usage: 56.13 MB\n",
            "GPU memory reserved: 848.00 MB\n",
            "Test Loss: 0.0844, Test Accuracy: 0.3190\n",
            "Test Time: 5.52s\n",
            "GPU memory usage during test: 49.60 MB\n",
            "GPU memory reserved during test: 202.00 MB\n",
            "Training on MNIST\n",
            "Epoch 1/10 - Time: 46.02s\n",
            "Validation Loss: 0.0042, Validation Accuracy: 0.9609\n",
            "GPU memory usage: 61.77 MB\n",
            "GPU memory reserved: 852.00 MB\n",
            "Epoch 2/10 - Time: 45.93s\n",
            "Validation Loss: 0.0031, Validation Accuracy: 0.9723\n",
            "GPU memory usage: 61.77 MB\n",
            "GPU memory reserved: 852.00 MB\n",
            "Epoch 3/10 - Time: 46.10s\n",
            "Validation Loss: 0.0035, Validation Accuracy: 0.9658\n",
            "GPU memory usage: 61.77 MB\n",
            "GPU memory reserved: 852.00 MB\n",
            "Epoch 4/10 - Time: 46.00s\n",
            "Validation Loss: 0.0027, Validation Accuracy: 0.9735\n",
            "GPU memory usage: 61.77 MB\n",
            "GPU memory reserved: 852.00 MB\n",
            "Epoch 5/10 - Time: 46.08s\n",
            "Validation Loss: 0.0026, Validation Accuracy: 0.9758\n",
            "GPU memory usage: 62.02 MB\n",
            "GPU memory reserved: 852.00 MB\n",
            "Epoch 6/10 - Time: 46.04s\n",
            "Validation Loss: 0.0032, Validation Accuracy: 0.9706\n",
            "GPU memory usage: 61.77 MB\n",
            "GPU memory reserved: 852.00 MB\n",
            "Epoch 7/10 - Time: 45.91s\n",
            "Validation Loss: 0.0029, Validation Accuracy: 0.9750\n",
            "GPU memory usage: 61.77 MB\n",
            "GPU memory reserved: 852.00 MB\n",
            "Epoch 8/10 - Time: 46.23s\n",
            "Validation Loss: 0.0026, Validation Accuracy: 0.9772\n",
            "GPU memory usage: 61.77 MB\n",
            "GPU memory reserved: 852.00 MB\n",
            "Epoch 9/10 - Time: 45.84s\n",
            "Validation Loss: 0.0027, Validation Accuracy: 0.9752\n",
            "GPU memory usage: 61.77 MB\n",
            "GPU memory reserved: 852.00 MB\n",
            "Epoch 10/10 - Time: 45.91s\n",
            "Validation Loss: 0.0029, Validation Accuracy: 0.9751\n",
            "GPU memory usage: 61.77 MB\n",
            "GPU memory reserved: 852.00 MB\n",
            "Test Loss: 0.0030, Test Accuracy: 0.9732\n",
            "Test Time: 5.64s\n",
            "GPU memory usage during test: 49.11 MB\n",
            "GPU memory reserved during test: 200.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10, CIFAR100, MNIST\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import time\n",
        "import psutil\n",
        "import os\n",
        "import gc\n",
        "import pandas as pd\n",
        "\n",
        "# The full classes are assumed to be already provided based on your previous implementation\n",
        "\n",
        "# Define transformations for the dataset\n",
        "transform_cifar = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "test_transform_cifar = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.4914, 0.4822, 0.4465), std=(0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_mnist = transforms.Compose([\n",
        "    transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "def get_dataloaders(dataset, transform, test_transform, batch_size=32):\n",
        "    if dataset == 'CIFAR10':\n",
        "        train_dataset = CIFAR10(root='data', train=True, transform=transform, download=True)\n",
        "        test_dataset = CIFAR10(root='data', train=False, transform=test_transform, download=True)\n",
        "    elif dataset == 'CIFAR100':\n",
        "        train_dataset = CIFAR100(root='data', train=True, transform=transform, download=True)\n",
        "        test_dataset = CIFAR100(root='data', train=False, transform=test_transform, download=True)\n",
        "    elif dataset == 'MNIST':\n",
        "        train_dataset = MNIST(root='data', train=True, transform=transform, download=True)\n",
        "        test_dataset = MNIST(root='data', train=False, transform=test_transform, download=True)\n",
        "    else:\n",
        "        raise ValueError(\"Dataset not supported\")\n",
        "\n",
        "    train_size = int(0.8 * len(train_dataset))\n",
        "    val_size = len(train_dataset) - train_size\n",
        "    train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, val_loader, test_loader\n",
        "\n",
        "def calculate_memory():\n",
        "    return psutil.virtual_memory()._asdict()\n",
        "\n",
        "def train_and_evaluate(model, train_loader, val_loader, device, dataset, n_epochs=10):\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "    model.to(device)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        start_time = time.time()\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        end_time = time.time()\n",
        "        epoch_time = end_time - start_time\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        correct = 0\n",
        "        with torch.no_grad():\n",
        "            for images, labels in val_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = model(images)\n",
        "                val_loss += criterion(outputs, labels).item()\n",
        "                pred = outputs.argmax(dim=1, keepdim=True)\n",
        "                correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "\n",
        "        val_loss /= len(val_loader.dataset)\n",
        "        val_accuracy = correct / len(val_loader.dataset)\n",
        "\n",
        "        gpu_memory_allocated = torch.cuda.memory_allocated() / 1024**2\n",
        "        gpu_memory_reserved = torch.cuda.memory_reserved() / 1024**2\n",
        "\n",
        "        results.append({\n",
        "            'dataset': dataset,\n",
        "            'epoch': epoch + 1,\n",
        "            'epoch_time': epoch_time,\n",
        "            'val_loss': val_loss,\n",
        "            'val_accuracy': val_accuracy,\n",
        "            'gpu_memory_allocated_MB': gpu_memory_allocated,\n",
        "            'gpu_memory_reserved_MB': gpu_memory_reserved\n",
        "        })\n",
        "\n",
        "        print(f'Epoch {epoch+1}/{n_epochs} - Time: {epoch_time:.2f}s')\n",
        "        print(f'Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}')\n",
        "        print(f'GPU memory usage: {gpu_memory_allocated:.2f} MB')\n",
        "        print(f'GPU memory reserved: {gpu_memory_reserved:.2f} MB')\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "    return results\n",
        "\n",
        "def test(model, test_loader, device):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    start_time = time.time()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            test_loss += criterion(outputs, labels).item()\n",
        "            pred = outputs.argmax(dim=1, keepdim=True)\n",
        "            correct += pred.eq(labels.view_as(pred)).sum().item()\n",
        "    end_time = time.time()\n",
        "    test_time = end_time - start_time\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = correct / len(test_loader.dataset)\n",
        "\n",
        "    gpu_memory_allocated = torch.cuda.memory_allocated() / 1024**2\n",
        "    gpu_memory_reserved = torch.cuda.memory_reserved() / 1024**2\n",
        "\n",
        "    print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
        "    print(f'Test Time: {test_time:.2f}s')\n",
        "    print(f'GPU memory usage during test: {gpu_memory_allocated:.2f} MB')\n",
        "    print(f'GPU memory reserved during test: {gpu_memory_reserved:.2f} MB')\n",
        "\n",
        "    return test_loss, test_accuracy, test_time, gpu_memory_allocated, gpu_memory_reserved\n",
        "\n",
        "def main():\n",
        "    datasets = ['CIFAR10', 'CIFAR100', 'MNIST']\n",
        "    batch_size = 32\n",
        "    n_epochs = 10\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    all_results = []\n",
        "\n",
        "    for dataset in datasets:\n",
        "        print(f\"Training on {dataset}\")\n",
        "        if dataset == 'MNIST':\n",
        "            train_loader, val_loader, test_loader = get_dataloaders(dataset, transform_mnist, transform_mnist, batch_size)\n",
        "        else:\n",
        "            train_loader, val_loader, test_loader = get_dataloaders(dataset, transform_cifar, test_transform_cifar, batch_size)\n",
        "\n",
        "        n_layers = 2\n",
        "        n_channel = 64\n",
        "        n_hidden = 128\n",
        "        n_output = 10 if dataset != 'CIFAR100' else 100\n",
        "        image_size = 32\n",
        "        patch_size = 2\n",
        "        n_image_channel = 3 if dataset != 'MNIST' else 1\n",
        "\n",
        "        model = KAN_Mixer(n_layers, n_channel, n_hidden, n_output, image_size, patch_size, n_image_channel)\n",
        "\n",
        "        # Reset GPU memory stats\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        train_results = train_and_evaluate(model, train_loader, val_loader, device, dataset, n_epochs)\n",
        "        test_loss, test_accuracy, test_time, test_gpu_allocated, test_gpu_reserved = test(model, test_loader, device)\n",
        "\n",
        "        for result in train_results:\n",
        "            result.update({\n",
        "                'test_loss': test_loss,\n",
        "                'test_accuracy': test_accuracy,\n",
        "                'test_time': test_time,\n",
        "                'test_gpu_memory_allocated_MB': test_gpu_allocated,\n",
        "                'test_gpu_memory_reserved_MB': test_gpu_reserved\n",
        "            })\n",
        "\n",
        "        all_results.extend(train_results)\n",
        "\n",
        "    # Save all results to one DataFrame\n",
        "    df = pd.DataFrame(all_results)\n",
        "    df.to_csv('all_datasets_results.csv', index=False)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqrDe4C4onRA",
        "outputId": "3e5db444-2565-4479-efbc-f2dcd9d683ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on CIFAR10\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/10 - Time: 110.14s\n",
            "Validation Loss: 0.0464, Validation Accuracy: 0.4614\n",
            "GPU memory usage: 77.56 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 2/10 - Time: 110.16s\n",
            "Validation Loss: 0.0407, Validation Accuracy: 0.5320\n",
            "GPU memory usage: 77.56 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 3/10 - Time: 110.15s\n",
            "Validation Loss: 0.0392, Validation Accuracy: 0.5464\n",
            "GPU memory usage: 77.56 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 4/10 - Time: 110.16s\n",
            "Validation Loss: 0.0368, Validation Accuracy: 0.5792\n",
            "GPU memory usage: 77.56 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 5/10 - Time: 110.13s\n",
            "Validation Loss: 0.0351, Validation Accuracy: 0.5996\n",
            "GPU memory usage: 77.56 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 6/10 - Time: 110.17s\n",
            "Validation Loss: 0.0339, Validation Accuracy: 0.6132\n",
            "GPU memory usage: 77.56 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 7/10 - Time: 110.12s\n",
            "Validation Loss: 0.0329, Validation Accuracy: 0.6232\n",
            "GPU memory usage: 77.56 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 8/10 - Time: 110.15s\n",
            "Validation Loss: 0.0320, Validation Accuracy: 0.6338\n",
            "GPU memory usage: 77.56 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 9/10 - Time: 110.13s\n",
            "Validation Loss: 0.0321, Validation Accuracy: 0.6349\n",
            "GPU memory usage: 77.56 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 10/10 - Time: 110.12s\n",
            "Validation Loss: 0.0311, Validation Accuracy: 0.6494\n",
            "GPU memory usage: 77.56 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Test Loss: 0.0294, Test Accuracy: 0.6693\n",
            "Test Time: 11.26s\n",
            "GPU memory usage during test: 63.70 MB\n",
            "GPU memory reserved during test: 358.00 MB\n",
            "Training on CIFAR100\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Epoch 1/10 - Time: 110.14s\n",
            "Validation Loss: 0.1116, Validation Accuracy: 0.1526\n",
            "GPU memory usage: 78.44 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 2/10 - Time: 110.15s\n",
            "Validation Loss: 0.1003, Validation Accuracy: 0.2171\n",
            "GPU memory usage: 78.44 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 3/10 - Time: 110.19s\n",
            "Validation Loss: 0.0932, Validation Accuracy: 0.2625\n",
            "GPU memory usage: 78.44 MB\n",
            "GPU memory reserved: 1704.00 MB\n",
            "Epoch 4/10 - Time: 110.17s\n",
            "Validation Loss: 0.0904, Validation Accuracy: 0.2734\n",
            "GPU memory usage: 78.44 MB\n",
            "GPU memory reserved: 1706.00 MB\n",
            "Epoch 5/10 - Time: 110.17s\n",
            "Validation Loss: 0.0888, Validation Accuracy: 0.2833\n",
            "GPU memory usage: 78.44 MB\n",
            "GPU memory reserved: 1706.00 MB\n",
            "Epoch 6/10 - Time: 110.14s\n",
            "Validation Loss: 0.0854, Validation Accuracy: 0.3085\n",
            "GPU memory usage: 78.44 MB\n",
            "GPU memory reserved: 1706.00 MB\n",
            "Epoch 7/10 - Time: 110.14s\n",
            "Validation Loss: 0.0833, Validation Accuracy: 0.3182\n",
            "GPU memory usage: 78.44 MB\n",
            "GPU memory reserved: 1706.00 MB\n",
            "Epoch 8/10 - Time: 110.15s\n",
            "Validation Loss: 0.0830, Validation Accuracy: 0.3199\n",
            "GPU memory usage: 78.44 MB\n",
            "GPU memory reserved: 1706.00 MB\n",
            "Epoch 9/10 - Time: 110.18s\n",
            "Validation Loss: 0.0815, Validation Accuracy: 0.3367\n",
            "GPU memory usage: 78.44 MB\n",
            "GPU memory reserved: 1706.00 MB\n",
            "Epoch 10/10 - Time: 110.16s\n",
            "Validation Loss: 0.0812, Validation Accuracy: 0.3412\n",
            "GPU memory usage: 78.44 MB\n",
            "GPU memory reserved: 1706.00 MB\n",
            "Test Loss: 0.0793, Test Accuracy: 0.3549\n",
            "Test Time: 11.22s\n",
            "GPU memory usage during test: 64.14 MB\n",
            "GPU memory reserved during test: 398.00 MB\n",
            "Training on MNIST\n",
            "Epoch 1/10 - Time: 132.08s\n",
            "Validation Loss: 0.0034, Validation Accuracy: 0.9671\n",
            "GPU memory usage: 90.36 MB\n",
            "GPU memory reserved: 1692.00 MB\n",
            "Epoch 2/10 - Time: 132.14s\n",
            "Validation Loss: 0.0031, Validation Accuracy: 0.9685\n",
            "GPU memory usage: 91.36 MB\n",
            "GPU memory reserved: 1692.00 MB\n",
            "Epoch 3/10 - Time: 132.15s\n",
            "Validation Loss: 0.0027, Validation Accuracy: 0.9736\n",
            "GPU memory usage: 91.36 MB\n",
            "GPU memory reserved: 1692.00 MB\n",
            "Epoch 4/10 - Time: 132.13s\n",
            "Validation Loss: 0.0023, Validation Accuracy: 0.9778\n",
            "GPU memory usage: 90.36 MB\n",
            "GPU memory reserved: 1692.00 MB\n",
            "Epoch 5/10 - Time: 132.12s\n",
            "Validation Loss: 0.0024, Validation Accuracy: 0.9762\n",
            "GPU memory usage: 91.36 MB\n",
            "GPU memory reserved: 1692.00 MB\n",
            "Epoch 6/10 - Time: 132.12s\n",
            "Validation Loss: 0.0022, Validation Accuracy: 0.9778\n",
            "GPU memory usage: 90.36 MB\n",
            "GPU memory reserved: 1692.00 MB\n",
            "Epoch 7/10 - Time: 132.11s\n",
            "Validation Loss: 0.0030, Validation Accuracy: 0.9743\n",
            "GPU memory usage: 90.36 MB\n",
            "GPU memory reserved: 1692.00 MB\n",
            "Epoch 8/10 - Time: 132.10s\n",
            "Validation Loss: 0.0024, Validation Accuracy: 0.9778\n",
            "GPU memory usage: 90.36 MB\n",
            "GPU memory reserved: 1692.00 MB\n",
            "Epoch 9/10 - Time: 132.13s\n",
            "Validation Loss: 0.0029, Validation Accuracy: 0.9752\n",
            "GPU memory usage: 90.36 MB\n",
            "GPU memory reserved: 1692.00 MB\n",
            "Epoch 10/10 - Time: 132.12s\n",
            "Validation Loss: 0.0023, Validation Accuracy: 0.9811\n",
            "GPU memory usage: 91.36 MB\n",
            "GPU memory reserved: 1692.00 MB\n",
            "Test Loss: 0.0021, Test Accuracy: 0.9816\n",
            "Test Time: 11.32s\n",
            "GPU memory usage during test: 63.41 MB\n",
            "GPU memory reserved during test: 362.00 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "QK89qZoh4CmH"
      }
    }
  ]
}